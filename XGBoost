import os
import logging
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, classification_report, f1_score, 
    precision_score, recall_score, make_scorer
)
from xgboost import XGBClassifier
from imblearn.under_sampling import RandomUnderSampler

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("model_training.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def load_and_preprocess_data(file_path):
    """
    Load and preprocess dataset
    
    Args:
        file_path (str): Path to CSV file
        
    Returns:
        tuple: Feature array and label array
    """
    try:
        # Load data
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Data file not found: {file_path}")
            
        data = pd.read_csv(file_path)
        logger.info(f"Successfully loaded data with {data.shape[0]} rows and {data.shape[1]} columns")
        
        # Data preprocessing
        if "V1" in data.columns:
            data.drop("V1", axis=1, inplace=True)
            logger.info("Dropped column 'V1'")
            
        # Convert numeric columns
        numeric_columns = data.columns[1:]
        data[numeric_columns] = data[numeric_columns].apply(pd.to_numeric, errors='coerce')
        
        # Handle missing values
        missing_count = data.isnull().sum().sum()
        if missing_count > 0:
            data.dropna(inplace=True)
            logger.info(f"Handled missing values by dropping {missing_count} records")
            
        # Convert labels
        if 'label' not in data.columns:
            raise ValueError("Column 'label' not found in dataset")
            
        data['label'] = data['label'].astype('float32')
        
        # Extract features and labels
        X = data.drop('label', axis=1).values
        y = data['label'].values.astype(int) - 1  # Convert labels to 0-5 range
        
        logger.info(f"Data preprocessing completed. Features shape: {X.shape}, Label range: {np.min(y)}-{np.max(y)}")
        return X, y
    
    except Exception as e:
        logger.error(f"Data loading and preprocessing failed: {str(e)}")
        raise

def prepare_data(X, y, test_size=0.2, random_state=42, handle_imbalance=False):
    """
    Prepare training and test data
    
    Args:
        X (array-like): Feature array
        y (array-like): Label array
        test_size (float): Test set proportion
        random_state (int): Random seed
        handle_imbalance (bool): Whether to handle class imbalance
        
    Returns:
        tuple: Training and test datasets
    """
    try:
        # Split data into training and test sets
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state, shuffle=True
        )
        
        logger.info(f"Training set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}")
        
        # Feature scaling
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Handle class imbalance
        if handle_imbalance:
            rus = RandomUnderSampler(random_state=random_state)
            X_train_scaled, y_train = rus.fit_resample(X_train_scaled, y_train)
            logger.info(f"After handling class imbalance, training set size: {X_train_scaled.shape[0]}")
        
        return X_train_scaled, X_test_scaled, y_train, y_test
    
    except Exception as e:
        logger.error(f"Data preparation failed: {str(e)}")
        raise

def create_xgboost_model():
    """
    Create XGBoost classification model
    
    Returns:
        XGBClassifier: Configured XGBoost model
    """
    return XGBClassifier(
        max_depth=3,
        learning_rate=0.1,
        objective='multi:softmax',
        num_class=6,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        use_label_encoder=False,
        eval_metric='mlogloss'
    )

def perform_cross_validation(model, X_train, y_train, cv=5):
    """
    Perform cross-validation
    
    Args:
        model: Model object
        X_train: Training features
        y_train: Training labels
        cv: Number of cross-validation folds
        
    Returns:
        dict: Cross-validation results
    """
    try:
        # Define evaluation metrics
        scoring = {
            'accuracy': 'accuracy',
            'f1_score': make_scorer(f1_score, average='weighted'),
            'precision': make_scorer(precision_score, average='weighted'),
            'recall': make_scorer(recall_score, average='weighted')
        }
        
        # Perform cross-validation
        cv_results = cross_validate(model, X_train, y_train, cv=cv, scoring=scoring)
        
        # Log cross-validation results
        logger.info("\n----- Cross-Validation Scores (Training Set) -----")
        logger.info(f"Average Accuracy:  {cv_results['test_accuracy'].mean():.4f}")
        logger.info(f"Average F1 Score:  {cv_results['test_f1_score'].mean():.4f}")
        logger.info(f"Average Precision: {cv_results['test_precision'].mean():.4f}")
        logger.info(f"Average Recall:    {cv_results['test_recall'].mean():.4f}")
        
        return cv_results
    
    except Exception as e:
        logger.error(f"Cross-validation failed: {str(e)}")
        raise

def train_and_evaluate_model(model, X_train, X_test, y_train, y_test):
    """
    Train and evaluate the model
    
    Args:
        model: Model object
        X_train: Training features
        X_test: Test features
        y_train: Training labels
        y_test: Test labels
        
    Returns:
        tuple: Trained model and evaluation results
    """
    try:
        # Train the model
        model.fit(X_train, y_train)
        logger.info("Model training completed")
        
        # Evaluate on test set
        y_test_pred = model.predict(X_test)
        test_accuracy = accuracy_score(y_test, y_test_pred)
        
        logger.info("\n----- Test Set Evaluation Results -----")
        logger.info(f"Test Accuracy: {test_accuracy:.4f}")
        logger.info("Classification Report (Test Set):")
        logger.info(classification_report(y_test, y_test_pred))
        
        # Evaluate on training set
        y_train_pred = model.predict(X_train)
        train_accuracy = accuracy_score(y_train, y_train_pred)
        
        logger.info("\n----- Training Set Evaluation Results -----")
        logger.info(f"Training Accuracy: {train_accuracy:.4f}")
        logger.info("Classification Report (Training Set):")
        logger.info(classification_report(y_train, y_train_pred))
        
        return model, {
            'test_accuracy': test_accuracy,
            'train_accuracy': train_accuracy,
            'y_test_pred': y_test_pred,
            'y_train_pred': y_train_pred
        }
    
    except Exception as e:
        logger.error(f"Model training and evaluation failed: {str(e)}")
        raise

def main():
    """
    Main function to control the entire model training and evaluation pipeline
    """
    try:
        logger.info("Starting model training pipeline...")
        
        # Data path
        file_path = r"C:\Users\13449\Desktop\大创\final5.csv"
        
        # Load and preprocess data
        X, y = load_and_preprocess_data(file_path)
        
        # Prepare data
        X_train, X_test, y_train, y_test = prepare_data(
            X, y, test_size=0.2, random_state=42, handle_imbalance=False
        )
        
        # Create model
        model = create_xgboost_model()
        
        # Cross-validation
        perform_cross_validation(model, X_train, y_train, cv=5)
        
        # Train and evaluate model
        trained_model, evaluation_results = train_and_evaluate_model(
            model, X_train, X_test, y_train, y_test
        )
        
        logger.info("Model training and evaluation pipeline completed!")
        
    except Exception as e:
        logger.critical(f"Main program execution failed: {str(e)}", exc_info=True)

if __name__ == "__main__":
    main()
