import os
import logging
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, accuracy_score
from lightgbm import LGBMClassifier

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("lgbm_training.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def load_and_preprocess_data(file_path):
    """
    Load and preprocess dataset with error handling
    
    Args:
        file_path (str): Path to CSV file
        
    Returns:
        pd.DataFrame: Preprocessed dataset
        
    Raises:
        FileNotFoundError: If data file not found
        ValueError: If label column missing
    """
    try:
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Data file not found: {file_path}")
            
        data = pd.read_csv(file_path)
        logger.info(f"Loaded data with {data.shape[0]} rows and {data.shape[1]} columns")
        
        # Drop unused column
        if "V1" in data.columns:
            data.drop("V1", axis=1, inplace=True)
            logger.info("Dropped column 'V1'")
        
        # Convert numeric columns
        numeric_columns = data.columns[1:]
        data[numeric_columns] = data[numeric_columns].apply(pd.to_numeric, errors='coerce')
        
        # Handle missing values
        missing_before = data.isnull().sum().sum()
        if missing_before > 0:
            data.dropna(inplace=True)
            missing_after = data.isnull().sum().sum()
            logger.info(f"Removed {missing_before - missing_after} rows with missing values")
        
        # Check for label column
        if 'label' not in data.columns:
            raise ValueError("Label column 'label' not found in dataset")
            
        return data
    
    except Exception as e:
        logger.error(f"Data processing failed: {str(e)}")
        raise

def prepare_features_and_labels(data):
    """
    Prepare features and labels with label encoding
    
    Args:
        data (pd.DataFrame): Preprocessed dataset
        
    Returns:
        tuple: (X, y) feature matrix and label array
    """
    try:
        # Encode label column
        label_encoder = LabelEncoder()
        data['label'] = label_encoder.fit_transform(data['label'].astype(str))
        unique_labels = len(np.unique(data['label']))
        logger.info(f"Label encoded to {unique_labels} classes: {dict(zip(label_encoder.classes_, range(unique_labels)))}")
        
        # Extract features and labels
        X = data.drop('label', axis=1).values
        y = data['label'].values
        
        logger.info(f"Feature matrix shape: {X.shape}, Label array shape: {y.shape}")
        return X, y
    
    except Exception as e:
        logger.error(f"Feature/labels preparation failed: {str(e)}")
        raise

def split_and_scale_data(X, y, test_size=0.2, random_state=42):
    """
    Split data into train/test and apply feature scaling
    
    Args:
        X (array-like): Feature matrix
        y (array-like): Label array
        test_size (float): Proportion of test set
        random_state (int): Random seed for reproducibility
        
    Returns:
        tuple: (X_train_scaled, X_test_scaled, y_train, y_test)
    """
    try:
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state, shuffle=True
        )
        logger.info(f"Data split: {X_train.shape[0]} train samples, {X_test.shape[0]} test samples")
        
        # Feature scaling
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        logger.info("Feature scaling completed")
        
        return X_train_scaled, X_test_scaled, y_train, y_test
    
    except Exception as e:
        logger.error(f"Data splitting/scaling failed: {str(e)}")
        raise

def create_lgbm_model(objective='binary', num_classes=None):
    """
    Create configured LGBMClassifier with weighted metrics support
    
    Args:
        objective (str): LGBM objective function
        num_classes (int): Number of classes for multi-class tasks
        
    Returns:
        LGBMClassifier: Configured model
    """
    try:
        # Adjust parameters based on objective
        params = {
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'max_depth': -1,
            'learning_rate': 0.1,
            'n_estimators': 500,
            'feature_fraction': 0.9,
            'bagging_fraction': 0.8,
            'bagging_freq': 5,
            'verbose': 0,
            'random_state': 42,
            'n_jobs': -1,
            'importance_type': 'split'
        }
        
        # Set objective based on problem type
        if objective == 'binary':
            params.update({'objective': 'binary'})
        elif objective == 'multiclass' and num_classes:
            params.update({
                'objective': 'multiclass',
                'num_classes': num_classes
            })
        else:
            raise ValueError(f"Unsupported objective: {objective}")
            
        logger.info(f"Created LGBM model with objective: {objective}")
        return LGBMClassifier(**params)
    
    except Exception as e:
        logger.error(f"Model creation failed: {str(e)}")
        raise

def perform_cross_validation(model, X, y, cv=5, scoring='accuracy'):
    """
    Perform cross-validation with weighted metrics
    
    Args:
        model: Scikit-learn compatible model
        X (array-like): Features
        y (array-like): Labels
        cv (int): Number of cross-validation folds
        scoring (str/list): Evaluation metric(s)
        
    Returns:
        tuple: (cv_scores, cv_mean)
    """
    try:
        # Execute cross-validation
        cv_scores = cross_val_score(
            model, X, y, cv=cv, scoring=scoring, n_jobs=-1
        )
        cv_mean = np.mean(cv_scores)
        
        # Log results with proper formatting
        logger.info(f"\n----- {cv}-fold Cross-Validation Results -----")
        logger.info(f"CV Scores: {[f'{score:.4f}' for score in cv_scores]}")
        logger.info(f"Mean CV {scoring}: {cv_mean:.4f}")
        print(f"Cross-validation scores: {[f'{score:.4f}' for score in cv_scores]}")
        print(f"Mean CV {scoring}: {cv_mean:.4f}")
        
        return cv_scores, cv_mean
    
    except Exception as e:
        logger.error(f"Cross-validation failed: {str(e)}")
        raise

def train_and_evaluate_model(model, X_train, X_test, y_train, y_test, print_reports=True):
    """
    Train model and evaluate with weighted metrics
    
    Args:
        model: Scikit-learn compatible model
        X_train: Training features
        X_test: Test features
        y_train: Training labels
        y_test: Test labels
        print_reports (bool): Whether to print classification reports
        
    Returns:
        tuple: (trained_model, evaluation_results)
    """
    try:
        # Train model
        model.fit(X_train, y_train)
        logger.info("Model training completed")
        
        # Evaluate on training set
        y_train_pred = model.predict(X_train)
        train_accuracy = accuracy_score(y_train, y_train_pred)
        
        # Evaluate on test set
        y_test_pred = model.predict(X_test)
        test_accuracy = accuracy_score(y_test, y_test_pred)
        
        # Prepare evaluation results
        results = {
            'train_accuracy': train_accuracy,
            'test_accuracy': test_accuracy,
            'y_train_pred': y_train_pred,
            'y_test_pred': y_test_pred
        }
        
        # Log and print results with weighted metrics
        logger.info("\n----- Training Set Evaluation -----")
        logger.info(f"Training Accuracy: {train_accuracy:.4f}")
        train_report = classification_report(
            y_train, y_train_pred, output_dict=True, average='weighted'
        )
        logger.info("Training Classification Report (Weighted):")
        for k, v in train_report.items():
            if k != 'macro avg' and k != 'weighted avg':  # Skip unnecessary rows
                logger.info(f"  {k}: {v:.4f}")
        logger.info(f"  weighted avg: precision={train_report['weighted avg']['precision']:.4f}, "
                    f"recall={train_report['weighted avg']['recall']:.4f}, "
                    f"f1-score={train_report['weighted avg']['f1-score']:.4f}")
        
        if print_reports:
            print(f"Training Accuracy: {train_accuracy:.4f}")
            print("Training Classification Report (Weighted):")
            print(classification_report(y_train, y_train_pred, average='weighted'))
        
        logger.info("\n----- Test Set Evaluation -----")
        logger.info(f"Test Accuracy: {test_accuracy:.4f}")
        test_report = classification_report(
            y_test, y_test_pred, output_dict=True, average='weighted'
        )
        logger.info("Test Classification Report (Weighted):")
        for k, v in test_report.items():
            if k != 'macro avg' and k != 'weighted avg':  # Skip unnecessary rows
                logger.info(f"  {k}: {v:.4f}")
        logger.info(f"  weighted avg: precision={test_report['weighted avg']['precision']:.4f}, "
                    f"recall={test_report['weighted avg']['recall']:.4f}, "
                    f"f1-score={test_report['weighted avg']['f1-score']:.4f}")
        
        if print_reports:
            print(f"Test Accuracy: {test_accuracy:.4f}")
            print("Test Classification Report (Weighted):")
            print(classification_report(y_test, y_test_pred, average='weighted'))
        
        return model, results
    
    except Exception as e:
        logger.error(f"Model training/evaluation failed: {str(e)}")
        raise

def main(file_path="file_path"):
    """
    Main execution pipeline for LGBM model training
    
    Args:
        file_path (str): Path to dataset CSV
    """
    try:
        logger.info("=== STARTING LGBM MODEL TRAINING PIPELINE ===")
        
        # 1. Load and preprocess data
        data = load_and_preprocess_data(file_path)
        
        # 2. Prepare features and labels
        X, y = prepare_features_and_labels(data)
        
        # 3. Split and scale data
        X_train_scaled, X_test_scaled, y_train, y_test = split_and_scale_data(X, y)
        
        # 4. Create LGBM model
        lgbm_model = create_lgbm_model()
        
        # 5. Perform cross-validation (use 'accuracy' for CV as default)
        perform_cross_validation(lgbm_model, X_train_scaled, y_train, cv=5)
        
        # 6. Train and evaluate model with weighted metrics
        trained_model, evaluation_results = train_and_evaluate_model(
            lgbm_model, X_train_scaled, X_test_scaled, y_train, y_test
        )
        
        logger.info("=== LGBM MODEL TRAINING COMPLETED SUCCESSFULLY ===")
        return trained_model, evaluation_results
        
    except Exception as e:
        logger.critical(f"Pipeline execution failed: {str(e)}", exc_info=True)
        raise

if __name__ == "__main__":
    # Example usage - replace with actual file path
    try:
        main(file_path="your_data.csv")
    except Exception as e:
        print(f"Execution error: {str(e)}")
